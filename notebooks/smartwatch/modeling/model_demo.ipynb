{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45950e91-e381-45cb-a9b2-c36bb5020bfb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Modeling with Deep Inference Pipelines: Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868973c8-03c2-4b0f-b9d4-6cf6a7ec10e5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36db9d44-51ac-44e4-aa71-00141a22a47a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "from nowoe.data.api.smartwatch.utilities.preparations import *\n",
    "import pandas\n",
    "import plotly_express as px\n",
    "import numpy\n",
    "import json\n",
    "import pickle\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict, List, Tuple, Union, Any, Iterator\n",
    "import torch.utils.data.dataloader\n",
    "from nowoe.data.api.smartwatch.utilities.timestamp import get_utc_date_from_utc_timestamp\n",
    "from nowoe.data.api.smartwatch.data_manager.module import SmartwatchDataManager\n",
    "from nowoe.deep_learning.data.dataset.smartwatch_study.single_slice import get_dataloaders, SmartwatchStudySingleSliceDataset, single_slice_collate_fn\n",
    "from nowoe.deep_learning.data.preprocessing.single_slice.normalization import MinMaxSingleSliceNormalization, ZScoreSingleSliceNormalization\n",
    "from nowoe.deep_learning.data.tensorizer.single_slice import CustomTensorizer\n",
    "from nowoe.deep_learning.data.augmentation.single_slice.sample_from_distribution.gaussian_mixtures import GaussianMixturesSingleSliceAugmentation\n",
    "from nowoe.deep_learning.pipeline.model.slice import LateFusedSeparateRNNSliceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4ecdf0-b0af-4843-81b2-a3cf86c83b26",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Getting the dataloaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d692009-4e40-4f5d-98f6-885d03e8b053",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-26 11:01:27,637 - nowoe.deep_learning.data.dataset.smartwatch_study.single_slice.interface - INFO - initializing data manager...\n",
      "2022-02-26 11:04:02,725 - nowoe.deep_learning.data.dataset.smartwatch_study.single_slice.interface - INFO - preparing the dataset...\n",
      "2022-02-26 11:04:03,005 - nowoe.deep_learning.data.dataset.smartwatch_study.single_slice.dataset - INFO - Loaded metadata from cache file: /home/shayan/phoenix/nowoe_framework/nowoe_framework/notebooks/smartwatch/dataset_cache/dataset-cache-2.pkl.gz\n",
      "2022-02-26 11:04:03,006 - nowoe.deep_learning.data.dataset.smartwatch_study.single_slice.interface - INFO - preparing samplers...\n",
      "2022-02-26 11:04:03,155 - nowoe.deep_learning.data.dataset.smartwatch_study.single_slice.sampler - WARNING - no samples for label 2.057142857142857 was found in the split: test\n",
      "2022-02-26 11:04:03,155 - nowoe.deep_learning.data.dataset.smartwatch_study.single_slice.sampler - WARNING - no samples for label 2.314285714285714 was found in the split: test\n",
      "2022-02-26 11:04:03,156 - nowoe.deep_learning.data.dataset.smartwatch_study.single_slice.sampler - WARNING - no samples for label 2.571428571428571 was found in the split: test\n",
      "2022-02-26 11:04:03,157 - nowoe.deep_learning.data.dataset.smartwatch_study.single_slice.sampler - WARNING - no samples for label 2.8285714285714283 was found in the split: test\n",
      "2022-02-26 11:04:03,157 - nowoe.deep_learning.data.dataset.smartwatch_study.single_slice.sampler - WARNING - no samples for label 3.0857142857142854 was found in the split: test\n",
      "2022-02-26 11:04:03,157 - nowoe.deep_learning.data.dataset.smartwatch_study.single_slice.sampler - WARNING - no samples for label 3.3428571428571425 was found in the split: test\n",
      "2022-02-26 11:04:03,158 - nowoe.deep_learning.data.dataset.smartwatch_study.single_slice.sampler - WARNING - no samples for label 3.5999999999999996 was found in the split: test\n"
     ]
    }
   ],
   "source": [
    "dataloaders = get_dataloaders(\n",
    "    batch_size=50,\n",
    "    root_dir='../../resources/warrior_wellness/Analysis/local_repo/',\n",
    "    subject_splits={\n",
    "        \"train\": [f'SWS_{i:02d}' for i in range(0,10)],\n",
    "        \"test\": [f'SWS_{i:02d}' for i in range(10,15)]},\n",
    "    dataset_config={\n",
    "        'slice_lengths': [3600],\n",
    "        'slice_time_step': (5 * 60),\n",
    "        'label_milestone_per_window': 1.0,\n",
    "        'metadata_cache_filepath': './dataset_cache/dataset-cache-2.pkl.gz',\n",
    "        'no_cache': False,\n",
    "        'parallel_threads': 10\n",
    "    },\n",
    "    sampler_configs=dict(\n",
    "       train=dict(\n",
    "           negative_sample_count=100,\n",
    "            positive_sample_count=50,\n",
    "            target_variable='overall_quantized_stress_value',\n",
    "           split_name=\"train\"\n",
    "       ),\n",
    "       test=dict(\n",
    "               negative_sample_count=100,\n",
    "            positive_sample_count=50,\n",
    "            target_variable='overall_quantized_stress_value',\n",
    "           split_name=\"test\"\n",
    "       )\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89167865-f126-4c3c-b2c1-04a92322b853",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Preparing a min-max normalizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02902460-f65c-4e8d-a344-dfb82b6bcf26",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-26 11:04:03,162 - nowoe.deep_learning.data.preprocessing.single_slice.normalization.base - INFO - [learning normalizers] sampling from the given dataloader...\n",
      "100%|███████████████████████████████████████████| 16/16 [00:07<00:00,  2.21it/s]\n",
      "2022-02-26 11:04:10,395 - nowoe.deep_learning.data.preprocessing.single_slice.normalization.base - INFO - [learning distributions] fitting models (of class <class 'sklearn.preprocessing._data.MinMaxScaler'>) to the distributions...\n",
      "2022-02-26 11:04:10,403 - nowoe.deep_learning.data.preprocessing.single_slice.normalization.base - INFO - [learning distributions] completed.\n"
     ]
    }
   ],
   "source": [
    "normalizer = MinMaxSingleSliceNormalization(\n",
    "    feature_names_per_data_source=dict(\n",
    "        daily=[\n",
    "            'heart_rate_tsvalue', \n",
    "            'distanceInMeters', \n",
    "            'floorsClimbed', \n",
    "            'bmrKilocalories', \n",
    "            'durationInSeconds',\n",
    "            'activeTimeInSeconds', \n",
    "            'activityStressDurationInSeconds',\n",
    "            'minHeartRateInBeatsPerMinute',\n",
    "            'stressDurationInSeconds',\n",
    "            'highStressDurationInSeconds',\n",
    "            'maxStressLevel',\n",
    "            'averageHeartRateInBeatsPerMinute',\n",
    "        ],\n",
    "        pulseOx=[\n",
    "            'durationInSeconds',\n",
    "            'spo2_tsvalue'\n",
    "        ],\n",
    "        respiration=[\n",
    "           'durationInSeconds',\n",
    "           'epoch_to_breath_tsvalue'\n",
    "        ],\n",
    "        stress=[\n",
    "            'durationInSeconds',\n",
    "            'stress_level_tsvalue'\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "normalizer.learn_normalizers(dataloaders['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83c7b71-8a08-49c8-8cd9-d7dcbea91dc8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Preparing the tensorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aaf4a45-ced8-43f3-819d-7c94973a343c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 16/16 [00:06<00:00,  2.51it/s]\n"
     ]
    }
   ],
   "source": [
    "tensorizer = CustomTensorizer(\n",
    "       config=dict(\n",
    "            timestamp_column='utc_timestamp',\n",
    "           value_config=dict(\n",
    "               daily=dict(\n",
    "                    embed=dict(\n",
    "                        columns=['activityType'],\n",
    "                        embedding_dim=[8],\n",
    "                    ),\n",
    "                    bring=[\n",
    "                        'durationInSeconds',\n",
    "                        'heart_rate_tsvalue', \n",
    "                        'distanceInMeters', \n",
    "                        'floorsClimbed', \n",
    "                        'bmrKilocalories', \n",
    "                        'activeTimeInSeconds', \n",
    "                        'activityStressDurationInSeconds',\n",
    "                        'minHeartRateInBeatsPerMinute',\n",
    "                        'stressDurationInSeconds',\n",
    "                        'highStressDurationInSeconds',\n",
    "                        'maxStressLevel',\n",
    "                        'averageHeartRateInBeatsPerMinute',\n",
    "                    ]\n",
    "               ),\n",
    "               pulseOx=dict(\n",
    "                   bring=[\n",
    "                       'durationInSeconds',\n",
    "                       'spo2_tsvalue'\n",
    "                   ]\n",
    "               ),\n",
    "               respiration=dict(\n",
    "                   bring=[\n",
    "                       'durationInSeconds',\n",
    "                       'epoch_to_breath_tsvalue'\n",
    "                   ]\n",
    "               ),\n",
    "               stress=dict(\n",
    "                   bring=[\n",
    "                       'durationInSeconds',\n",
    "                       'stress_level_tsvalue'\n",
    "                   ]\n",
    "               )\n",
    "           )\n",
    "       )\n",
    ")\n",
    "tensorizer.learn_embeddings(dataloaders['train'])\n",
    "tensorizer.build_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c4072d2-2ad3-4ba9-aa0e-2f743a106191",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def count_iter(dl):\n",
    "    c = 0\n",
    "    for _ in tqdm(dl):\n",
    "        c += 1\n",
    "    print(c)\n",
    "\n",
    "class A:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def a(self, dl):\n",
    "        count_iter(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b8cd75-4cd8-4ef4-bba5-5cb7fa662ab2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Getting the labels_layout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2afffb07-35fc-4a4c-b088-e9a80b56fad8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 16/16 [00:06<00:00,  2.48it/s]\n"
     ]
    }
   ],
   "source": [
    "labels_layout = set()\n",
    "for b in tqdm(dataloaders['train']):\n",
    "    labels_layout = labels_layout.union([e['overall_quantized_stress_value'] for e in b['meta']])\n",
    "labels_layout = sorted(list(labels_layout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46103ddd-382e-4218-9693-6e9f3db25f0a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Demo: Late Fusion Recurrent Neural Network - A Single Slice Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b9ebc1-9f07-4143-9dc5-4cc1bff8efa9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following configurations allow us to effectively define an instance of `LateFusedSeparateRNNSliceModel`, which is the model-family for single-slice models allowing the specific definition of a recurrent network for processing each data source separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "731e0ff0-2b73-444a-ab02-7c001ae493d8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shayan/anaconda3/envs/openmmlab/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "model = LateFusedSeparateRNNSliceModel(\n",
    "    config=dict(\n",
    "        branches=dict(\n",
    "            daily=dict(\n",
    "                rnn_model=\"LSTM\",\n",
    "                rnn_args=dict(\n",
    "                    input_size=20,\n",
    "                    hidden_size=32,\n",
    "                    bidirectional=True,\n",
    "                    batch_first=True,\n",
    "                    bias=False,\n",
    "                    dropout=0.2\n",
    "                ), #torch args\n",
    "                project_args=dict(\n",
    "                    input_dim=64,\n",
    "                    projection_dim=32\n",
    "                ),  # will be projected to this dimension if not None.\n",
    "            ),\n",
    "            respiration=dict(\n",
    "                rnn_model=\"LSTM\",\n",
    "                rnn_args=dict(\n",
    "                    input_size=2,\n",
    "                    hidden_size=4,\n",
    "                    bidirectional=True,\n",
    "                    batch_first=True,\n",
    "                    bias=False,\n",
    "                    dropout=0.2\n",
    "                ), #torch args\n",
    "                project_args=dict(\n",
    "                    input_dim=8,\n",
    "                    projection_dim=4\n",
    "                ),  # will be projected to this dimension if not None.\n",
    "            ),\n",
    "            pulseOx=dict(\n",
    "                rnn_model=\"LSTM\",\n",
    "                rnn_args=dict(\n",
    "                    input_size=2,\n",
    "                    hidden_size=4,\n",
    "                    bidirectional=True,\n",
    "                    batch_first=True,\n",
    "                    bias=False,\n",
    "                    dropout=0.2\n",
    "                ), #torch args\n",
    "                project_args=dict(\n",
    "                    input_dim=8,\n",
    "                    projection_dim=4\n",
    "                ),  # will be projected to this dimension if not None.\n",
    "            ),\n",
    "            stress=dict(\n",
    "                rnn_model=\"LSTM\",\n",
    "                rnn_args=dict(\n",
    "                    input_size=2,\n",
    "                    hidden_size=4,\n",
    "                    bidirectional=True,\n",
    "                    batch_first=True,\n",
    "                    bias=False,\n",
    "                    dropout=0.2\n",
    "                ), #torch args\n",
    "                project_args=dict(\n",
    "                    input_dim=8,\n",
    "                    projection_dim=4\n",
    "                ),  # will be projected to this dimension if not None.\n",
    "            )\n",
    "        ),\n",
    "        aggregation=dict(\n",
    "            method=\"concatenate\", # options are `mean` (this means all the branch reps have to be the same), `concatenate`\n",
    "            project_args=dict(\n",
    "                input_dim=44,\n",
    "                projection_dim=50), # the output of the given `method` will be projected to it (if not None).\n",
    "        ),\n",
    "        task=dict(\n",
    "            target_in_meta='overall_quantized_stress_value',\n",
    "            task_type='classification',\n",
    "            label_layout=[0.0,\n",
    "                          0.2571428571428571,\n",
    "                          0.5142857142857142,\n",
    "                          0.7714285714285714,\n",
    "                          1.0285714285714285,\n",
    "                          1.2857142857142856,\n",
    "                          1.5428571428571427,\n",
    "                          1.7999999999999998,\n",
    "                          2.057142857142857,\n",
    "                          2.314285714285714,\n",
    "                          2.571428571428571,\n",
    "                          2.8285714285714283,\n",
    "                          3.0857142857142854,\n",
    "                          3.3428571428571425,\n",
    "                          3.5999999999999996],\n",
    "            loss_class='CrossEntropyLoss',\n",
    "            loss_args=dict(),\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16daa4f7-b413-4baf-98e9-b425d4ff5424",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Single batch demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8a4423-1379-4edb-9e4f-21a4d40b8125",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now let's read, process, and make inferences using the batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf15e76-dd75-42f8-a04e-69b0782e7fb0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "my_iter = iter(dataloaders['train'])\n",
    "batch = next(my_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e82aa23-9b2b-4fe4-810c-c7849df10022",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "processed_batch = tensorizer(normalizer(batch))\n",
    "# packed_batch = pack_single_slice_batch_for_rnn(processed_batch, processed_batch['slice'][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "737019e6-c30d-47f3-84cb-bf3de30a355a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model_outputs', 'loss_outputs'])\n"
     ]
    }
   ],
   "source": [
    "out = model(processed_batch, mode='train')\n",
    "print(out.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15f7c31d-c99c-4882-8b82-05ff3831d830",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model_outputs', 'loss_outputs'])\n"
     ]
    }
   ],
   "source": [
    "out = model(processed_batch, mode='test')\n",
    "print(out.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60795a8e-72ed-4160-b171-2610c4766e1e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['latent_representations', 'logits', 'y_hat', 'loss_eval'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['model_outputs'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "282c7f13-1430-4c7a-bc91-cd7f262fa1b8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11,  6, 11,  6, 11, 11, 11, 11, 11, 11,  7, 11, 11, 11,  7, 11, 11,\n",
       "       11, 11, 11, 11, 11,  7, 11, 11, 11,  7, 11, 11,  6, 11,  7, 11, 11,\n",
       "       11,  7, 11,  7, 11, 11, 11, 11, 11, 11,  7, 11, 11, 11, 11,  7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['model_outputs']['y_hat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f31ee34c-b00b-4e5f-a8a2-9ba5dd7e5e11",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 16/16 [00:11<00:00,  1.38it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(dataloaders['train']):\n",
    "    processed_batch = tensorizer(normalizer(batch))\n",
    "    out = model(processed_batch, mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a307dfe9-5239-4d5a-8919-c27111f917a1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 9/9 [00:09<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(dataloaders['test']):\n",
    "    processed_batch = tensorizer(normalizer(batch))\n",
    "    out = model(processed_batch, mode='test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}