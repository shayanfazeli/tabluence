{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc904f76-4066-4e4e-81be-6c76eeb61186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional\n",
    "import torch.nn.utils.rnn\n",
    "\n",
    "\n",
    "def pack_single_slice_batch_for_rnn(\n",
    "        batch: Dict[str, List[torch.Tensor]],\n",
    "        data_sources_to_pack: List[str]) -> Dict[str, torch.nn.utils.rnn.PackedSequence]:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    batch: `Dict[str, List[torch.Tensor]]`, required\n",
    "        A single slice batch, containing 'slice' and 'meta' keys.\n",
    "\n",
    "    data_sources_to_pack: `List[str]`, required\n",
    "        The list of data sources to pack.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `Dict[str, torch.nn.utils.rnn.PackedSequence]`: The packed sequence\n",
    "    \"\"\"\n",
    "    packed_batch = dict()\n",
    "    for data_source in data_sources_to_pack:\n",
    "        packed_batch[data_source] = pack_batch_for_rnn(item_list=[e[data_source] for e in batch['slice']])\n",
    "    return packed_batch\n",
    "\n",
    "\n",
    "def pad_packed_sequence_for_rnn(packed_sequence: torch.nn.utils.rnn.PackedSequence) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Inverse of the `pack_batch_for_rnn` function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    packed_sequence: `torch.nn.utils.rnn.PackedSequence`, required\n",
    "        The packed sequence to be unpacked.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `Tuple[torch.Tensor, torch.Tensor]`: The unpacked sequence and the sequence lengths.\n",
    "    \"\"\"\n",
    "    unpacked_sequence, unpacked_lengths = torch.nn.utils.rnn.pad_packed_sequence(packed_sequence, batch_first=True)\n",
    "    return unpacked_sequence, unpacked_lengths\n",
    "\n",
    "\n",
    "def pack_batch_for_rnn(item_list: List[torch.Tensor]) -> torch.nn.utils.rnn.PackedSequence:\n",
    "    \"\"\"\n",
    "    Packs a batch of sequences for RNN.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    item_list: `List[torch.Tensor]`, required\n",
    "        The list of tensors, each of which is a sequence of shape `(sequence_length, rep_dim)`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `torch.nn.utils.rnn.PackedSequence`: The packed sequence\n",
    "    \"\"\"\n",
    "    # - preparing a placeholder for the sequence lengths\n",
    "    device = item_list[0].device\n",
    "    sequence_lengths = []\n",
    "\n",
    "    # - preparing a placeholder for the output\n",
    "    batch_tensor = []\n",
    "    max_sequence_length = int(numpy.max([x.shape[0] for x in item_list]))\n",
    "    rep_dim = item_list[0].shape[-1]\n",
    "    for x in item_list:\n",
    "        seq_len = x.shape[0]\n",
    "        if seq_len > 0:\n",
    "            batch_tensor.append(\n",
    "                torch.cat((x, torch.zeros(max_sequence_length - seq_len, rep_dim).to(device)))\n",
    "            )\n",
    "            sequence_lengths.append(seq_len)\n",
    "        else:\n",
    "            batch_tensor.append(- torch.ones(max_sequence_length, rep_dim).to(device))\n",
    "            sequence_lengths.append(1)\n",
    "\n",
    "    batch_tensor = torch.stack(batch_tensor)\n",
    "    sequence_lengths = torch.LongTensor(sequence_lengths)\n",
    "    packed_padded_sequence = torch.nn.utils.rnn.pack_padded_sequence(batch_tensor, sequence_lengths, batch_first=True, enforce_sorted=False)\n",
    "    return packed_padded_sequence\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee78bbf1-9664-47f3-89cf-6459daefa7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pack_batch_for_rnn([torch.rand(numpy.random.randint(5, 10), 4) for _ in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8486e82-9c04-4666-a2a6-ad1def9ce4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = torch.nn.LayerNorm((4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b79a7a0-9f06-453e-be51-7a0c96ebb0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.5443e-01, -1.5551e+00,  9.0086e-01, -2.0018e-01],\n",
       "        [ 1.4301e-01, -1.6750e+00,  7.7731e-01,  7.5471e-01],\n",
       "        [-4.8060e-01,  1.1181e+00, -1.3948e+00,  7.5726e-01],\n",
       "        [-1.5635e+00,  3.7445e-01,  1.1896e+00, -5.4160e-04]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm(torch.rand(4, 4) * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ba11c7f-b1a0-4d4f-891f-977d9fb9c731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af8972a-05d3-47df-a29c-134ea9fcd160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
